{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import git\n",
    "\n",
    "root = git.Repo('.', search_parent_directories=True).working_tree_dir\n",
    "os.chdir(root)\n",
    "print(f\"Changed working directory to {root}\")\n",
    "\n",
    "FFMPEG = '/mmfs1/gscratch/cse/bandhav/miniconda3/envs/avhubert_gpu/bin/ffmpeg'\n",
    "os.environ['PATH'] = f'{os.path.dirname(FFMPEG)}:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.avhubert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from IPython.display import HTML\n",
    "\n",
    "def play_video(video_path, width=200):\n",
    "    mp4 = open(video_path,'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return ipd.display(HTML(f\"\"\"\n",
    "    <video width={width} controls>\n",
    "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_predictor_path = f\"{root}/data/misc/shape_predictor_68_face_landmarks.dat\"\n",
    "mean_face_path = f\"{root}/data/misc/20words_mean_face.npy\"\n",
    "ckpt_path = f\"{root}/data/checkpoints/base_vox_433h.pt\"\n",
    "cnn_detector_path = f'{root}/data/misc/mmod_human_face_detector.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_roi(video_path, cnn_detector_path=None):\n",
    "    # Create a temporary file for mouth_roi_path\n",
    "    with tempfile.NamedTemporaryFile(suffix='.mp4') as mouth_roi:\n",
    "        mouth_roi_path = mouth_roi.name\n",
    "\n",
    "        # Call the preprocess_video function\n",
    "        preprocess_video(\n",
    "            video_path, mouth_roi_path, face_predictor_path, mean_face_path,\n",
    "            cnn_detector_path=cnn_detector_path\n",
    "        )\n",
    "\n",
    "        play_video(mouth_roi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.import_user_module(Namespace(user_dir=work_dir))\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tempfile\n",
    "from argparse import Namespace\n",
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "from fairseq.dataclass.configs import GenerationConfig\n",
    "from IPython.display import HTML\n",
    "\n",
    "def predict(video_path, models, saved_cfg, task):\n",
    "    num_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    data_dir = tempfile.mkdtemp()\n",
    "    tsv_cont = [\"/\\n\", f\"test-0\\t{video_path}\\t{None}\\t{num_frames}\\t{int(16_000*num_frames/25)}\\n\"]\n",
    "    label_cont = [\"DUMMY\\n\"]\n",
    "    with open(f\"{data_dir}/test.tsv\", \"w\") as fo:\n",
    "        fo.write(\"\".join(tsv_cont))\n",
    "    with open(f\"{data_dir}/test.wrd\", \"w\") as fo:\n",
    "        fo.write(\"\".join(label_cont))\n",
    "\n",
    "    modalities = [\"video\"]\n",
    "    gen_subset = \"test\"\n",
    "    gen_cfg = GenerationConfig(beam=20)\n",
    "    models = [model.eval().cuda() for model in models]\n",
    "\n",
    "    saved_cfg.task.modalities = modalities\n",
    "    saved_cfg.task.data = data_dir\n",
    "    saved_cfg.task.label_dir = data_dir\n",
    "    task = tasks.setup_task(saved_cfg.task)\n",
    "    task.load_dataset(gen_subset, task_cfg=saved_cfg.task)\n",
    "    generator = task.build_generator(models, gen_cfg)\n",
    "\n",
    "    def decode_fn(x):\n",
    "        dictionary = task.target_dictionary\n",
    "        symbols_ignore = generator.symbols_to_strip_from_output\n",
    "        symbols_ignore.add(dictionary.pad())\n",
    "        return task.datasets[gen_subset].label_processors[0].decode(x, symbols_ignore)\n",
    "\n",
    "    itr = task.get_batch_iterator(dataset=task.dataset(gen_subset)).next_epoch_itr(shuffle=False)\n",
    "    sample = next(itr)\n",
    "    sample = utils.move_to_cuda(sample)\n",
    "    hypos = task.inference_step(generator, models, sample)\n",
    "    ref = decode_fn(sample['target'][0].int().cpu())\n",
    "    hypo = hypos[0][0]['tokens'].int().cpu()\n",
    "    hypo = decode_fn(hypo)\n",
    "\n",
    "    return hypo\n",
    "\n",
    "video_path = f\"/mmfs1/gscratch/intelligentsystems/common_datasets/VoxCeleb2/mp4/id00017/7t6lfzvVaTM/00003.mp4\"\n",
    "\n",
    "play_video(video_path)\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.mp4') as mouth_roi:\n",
    "    mouth_roi_path = mouth_roi.name\n",
    "\n",
    "    # Call the preprocess_video function\n",
    "    preprocess_video(\n",
    "        video_path, mouth_roi_path, face_predictor_path, mean_face_path,\n",
    "        cnn_detector_path=cnn_detector_path\n",
    "    )\n",
    "    \n",
    "    ckpt_path = \"data/checkpoints/base_vox_433h.pt\"\n",
    "    hypo = predict(mouth_roi_path, models, saved_cfg, task)\n",
    "    print(f'{hypo=}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avhubert_gpu",
   "language": "python",
   "name": "avhubert_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
