{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import git\n",
    "\n",
    "root = git.Repo('.', search_parent_directories=True).working_tree_dir\n",
    "os.chdir(root)\n",
    "print(f\"Changed working directory to {root}\")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(asr_outputs)=64 len(vsr_outputs)=497\n",
      "Loaded 31341 reference and hypothesis pairs from ASR and VSR outputs.\n"
     ]
    }
   ],
   "source": [
    "asr_outputs = glob.glob('data/asr_outputs/*.csv')\n",
    "vsr_outputs = glob.glob('data/vsr_outputs/*.csv')\n",
    "print(f\"{len(asr_outputs)=} {len(vsr_outputs)=}\")\n",
    "\n",
    "# Concatenate ASR outputs in to a single dataframe\n",
    "def read_transcriptions(paths):\n",
    "    transcriptions = {}\n",
    "    for path in paths:\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # path_col is the first column\n",
    "        path_col, text_col = df.columns[:2]\n",
    "\n",
    "        # Filenames are of the format: `<prefix path>/id08701/z8t-KFSoYLI/00478.<ext>`\n",
    "        # We want to extract the filename `id08701/z8t-KFSoYLI/00478` from them\n",
    "        df[path_col] = df[path_col].apply(\n",
    "            lambda x: '/'.join(os.path.splitext(x)[0].split('/')[-3:])\n",
    "        )\n",
    "\n",
    "        for i, r in df.iterrows():\n",
    "            if r[text_col] == 'None' or pd.isna(r[text_col]):\n",
    "                continue\n",
    "            if 'language' in r and r['language'] != 'en':\n",
    "                continue\n",
    "            transcriptions[r[path_col]] = r[text_col].strip()\n",
    "    return transcriptions\n",
    "\n",
    "asr = read_transcriptions(asr_outputs)\n",
    "vsr = read_transcriptions(vsr_outputs)\n",
    "\n",
    "ref, hyp = [], []\n",
    "for k in vsr:\n",
    "    if k in asr:\n",
    "        ref.append(asr[k])\n",
    "        hyp.append(vsr[k])\n",
    "print(f\"Loaded {len(ref)} reference and hypothesis pairs from ASR and VSR outputs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.3899\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import jiwer\n",
    "\n",
    "_ref = copy.deepcopy(ref)\n",
    "_hyp = copy.deepcopy(hyp)\n",
    "random.shuffle(_ref)\n",
    "random.shuffle(_hyp)\n",
    "\n",
    "out = jiwer.process_words(\n",
    "    reference=ref,\n",
    "    hypothesis=hyp,\n",
    "    reference_transform=jiwer.wer_standardize, \n",
    "    hypothesis_transform=jiwer.wer_standardize\n",
    ")\n",
    "\n",
    "print(f\"WER: {out.wer:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
